<!DOCTYPE html>
<html lang="zh">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>训练一个可以自己玩游戏的智能体~</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
<link href="/2020/03/build-blog-system-by-pelican.html" rel="canonical" />
  <!-- Feed -->
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="此时此刻即是最好的~ Full Atom Feed" />
          <link href="/feeds/{slug}.atom.xml" type="application/atom+xml" rel="alternate" title="此时此刻即是最好的~ Categories Atom Feed" />

  <link href="/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="/theme/css/code_blocks/github.css" rel="stylesheet">


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->



    <meta name="description" content="这是一篇关于如何训练一个名义上的智能体让他自己学会玩游戏.">

    <meta name="author" content="zh">

    <meta name="tags" content="ReinforcementLearning">




<!-- Open Graph -->
<meta property="og:site_name" content="此时此刻即是最好的~"/>
<meta property="og:title" content="训练一个可以自己玩游戏的智能体~"/>
<meta property="og:description" content="这是一篇关于如何训练一个名义上的智能体让他自己学会玩游戏."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/2020/03/build-blog-system-by-pelican.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-03-01 00:00:00+08:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/zh">
<meta property="article:section" content="misc"/>
<meta property="article:tag" content="ReinforcementLearning"/>
<meta property="og:image" content="/theme/images/post-bg.jpg">

<!-- Twitter Card -->

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "训练一个可以自己玩游戏的智能体~",
  "headline": "训练一个可以自己玩游戏的智能体~",
  "datePublished": "2020-03-01 00:00:00+08:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "zh",
    "url": "/author/zh"
  },
  "image": "/theme/images/post-bg.jpg",
  "url": "/2020/03/build-blog-system-by-pelican.html",
  "description": "这是一篇关于如何训练一个名义上的智能体让他自己学会玩游戏."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="https://github.com/Mrzhang3389" role="presentation">我的GitHub主页</a></li>
          <li><a href="https://blog.csdn.net/zhanghao3389" role="presentation">我的csdn主页</a></li>
          <li><a href="mailto:zhanghao_3389@163.com" role="presentation">发email给我</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" >
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="/" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">训练一个可以自己玩游戏的智能体~</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="/author/zh">zh</a>
            | <time datetime="日 01 三月 2020">日 01 三月 2020</time>
        </span>
        <!-- TODO : Modified check -->
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <h1>如何让电脑学会自己玩游戏</h1>
<h4>所用技术: 强化学习 -&gt; Q_learning</h4>
<h4>环境搭建</h4>
<div class="highlight"><pre><span></span><code><span class="err">pip install pandas</span>
</code></pre></div>

<h4>可以解决问题的示例:</h4>
<ol>
<li>在计算机只知道它的动作只有<code>上下左右</code>和<code>复制粘贴</code>这六个动作的情况下 学会如何将上一行的文字复制到输出框</li>
<li>走一维, 二维或三维迷宫, 或者在有陷阱,有奖励的情况下. 获得最大收益或减少成本.</li>
<li>让计算机玩赌博游戏.   比如猜轮盘转出来的数字,猜对有奖励, 或者选择离开赌桌. 最长期的收益则是计算机选择离开赌桌. </li>
</ol>
<h4>该技术可玩游戏类型的限制:</h4>
<p>可玩: 状态有限, 动作有限. (其中一个 精确的解.)</p>
<p>不可玩: 状态无限 或 动作无限.  (其中一个 近似的解.)</p>
<h4>走迷宫实例参考:<a href="http://mnemstudio.org/path-finding-q-learning-tutorial.htm">走迷宫</a></h4>
<h4>游戏名: 寻宝者找宝藏</h4>
<h4>游戏环境说明:</h4>
<h2>—O————T</h2>
<p><code>O</code> 代表寻宝者的所在游戏中的位置</p>
<p><code>—</code> 代表路径</p>
<p><code>T</code> 代表宝藏的位置</p>
<p><code>O</code> 可执行的动作只有 <code>左</code> 和 <code>右</code></p>
<h4>智能体只知道:</h4>
<p>它找到宝藏就是最大化收益</p>
<p>它会的动作只有<code>左</code>和<code>右</code></p>
<p>它可随机出现在整个地图上的任何位置, 并试图找到宝藏</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 以下是对每个类所做的事情的详细描述</span>
<span class="k">class</span> <span class="nc">Game_env</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">get_env_feedback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="c1"># 输入给环境当前的状态 和 需要执行的动作</span>
        <span class="c1"># 返回下一个状态 和 下一个状态给的奖励</span>
        <span class="c1"># 例如输入: ---O-T  状态为:3  动作为: right</span>
        <span class="c1"># 那么输出: ----OT  状态为:4  奖励为: 0</span>

    <span class="k">def</span> <span class="nf">update_env</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="nb">round</span><span class="p">,</span> <span class="n">step_counter</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="c1"># 根据状态更新当前环境,并可视化.</span>
        <span class="c1"># 输入为 state=3</span>
        <span class="c1"># 输出为 可视化当前状态 终端显示: ---O-T  Treasure 宝物,财富.等意思...</span>
        <span class="c1"># round 和 step_counter 用于记录和显示 当前的回合数,和完成一回合游戏所使用的步数.可不使用</span>

<span class="k">class</span> <span class="nc">Play_game</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">build_q_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_states</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="c1"># 创建q表 用于指导智能体如何玩游戏</span>
        <span class="c1"># state     left  right</span>
        <span class="c1">#   0       0.0    0.0</span>
        <span class="c1">#   1       0.0    0.0</span>
        <span class="c1">#   2       0.0    0.0</span>
        <span class="c1">#   3       0.0    0.0</span>
        <span class="c1">#   4       0.0    0.0</span>
        <span class="c1"># 这里可以写成活的q表 判断如果没有此状态则添加.</span>
        <span class="c1"># 这里可以扩展到 二维的迷宫游戏或其它 状态有限 动作有限 的游戏</span>
        <span class="c1"># state    left     right  down   up</span>
        <span class="c1">#   0           0.0    0.0   0.0    0.0</span>
        <span class="c1">#   1           0.0    0.0   0.0    0.0</span>
        <span class="c1">#   2           0.0    0.0   0.0    0.0</span>
        <span class="c1">#   3           0.0    0.0   0.0    0.0</span>
        <span class="c1">#   4           0.0    0.0   0.0    0.0</span>


    <span class="k">def</span> <span class="nf">choose_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="c1"># 根据贪婪率选择随机动作或最大收益动作(电脑自动玩游戏)</span>
        <span class="c1"># 也可玩家手动指导智能体玩游戏只需将选择动作的代码改为键盘输入即可(人工指导智能体玩游戏)</span>
        <span class="c1"># 输入当前状态 例如: ---O-T  状态为: 3</span>
        <span class="c1"># 返回输出动作 例如: left 或者 right</span>


<span class="k">class</span> <span class="nc">Train</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">learning_round</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="c1"># 设置每个回合配置 如下:</span>
        <span class="c1"># 1. 初始状态 置零或随机</span>
        <span class="c1"># 2. 游戏状态 置为未完成</span>
        <span class="c1"># 3. 游戏进行步数 置零</span>
        <span class="c1"># 4. 游戏环境初始化</span>
        <span class="c1"># 开始学习q表</span>

    <span class="k">def</span> <span class="nf">learning_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">is_terminated</span><span class="p">,</span> <span class="nb">round</span><span class="p">,</span> <span class="n">step_count</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="c1"># 整个游戏初始化后就可以开始玩了.</span>
        <span class="c1"># 无限死循环 或者 玩多少步后强制退出都行</span>
        <span class="c1"># 1. 选择一个动作 -&gt; 得到一个动作</span>
        <span class="c1"># 2. 获得环境的反馈 -&gt; 得到 下一个状态 和 奖励</span>
        <span class="c1"># 3. 得到q真实的值 -&gt; 当前的状态 和 选择的动作 确定q真实的值</span>
        <span class="c1"># 4. 得到q估计的值 -&gt; 下一步动作的奖励 + 远见 * 下一个状态的所有动作值中的最大值</span>
        <span class="c1"># 5. 更新q表的值 -&gt; 学习率 * (q估计 - q现实)</span>
        <span class="c1"># 6. 更新当前的状态 -&gt; 当前状态为选择动作后的下一个状态</span>
        <span class="c1"># 7. 更新当前的环境</span>
        <span class="c1"># 8. 当前回合步数统计, 可省略.</span>
        <span class="c1"># 进入下一个回合, 重置游戏各项参数.重新开始玩.</span>

        <span class="c1"># state     left  right</span>
        <span class="c1">#   0       0.0    0.0</span>
        <span class="c1">#   1       0.0    0.0</span>
        <span class="c1">#   2       0.0    0.0</span>
        <span class="c1">#   3       0.0    0.0</span>
        <span class="c1">#   4       0.0    0.0</span>
</code></pre></div>

<h3>更新Q表:</h3>
<h5>更新后的值 = 更新前的值 + 学习率 * (奖励 + 远见 * q估计值 - q现实值)</h5>
<p>Q-learning原理参考: <a href="https://zh.wikipedia.org/wiki/Q%E5%AD%A6%E4%B9%A0">wiki百科</a></p>
<h3>所有代码</h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">class</span> <span class="nc">Game_env</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N_STATES</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">FRESH_TIME</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_STATES</span> <span class="o">=</span> <span class="n">N_STATES</span>   <span class="c1"># the length of the 1 dimensional world  状态长度</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">FRESH_TIME</span> <span class="o">=</span> <span class="n">FRESH_TIME</span>    <span class="c1"># fresh time for one move</span>

    <span class="k">def</span> <span class="nf">get_env_feedback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="s1">&#39;right&#39;</span><span class="p">:</span>    <span class="c1"># move right</span>
            <span class="k">if</span> <span class="n">state</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_STATES</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>   <span class="c1"># terminate 0 start</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="s1">&#39;terminal&#39;</span>
                <span class="n">reward</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>   <span class="c1"># move left</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">state</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span>  <span class="c1"># reach the wall</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span>

    <span class="k">def</span> <span class="nf">update_env</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="nb">round</span><span class="p">,</span> <span class="n">step_counter</span><span class="p">):</span>
        <span class="n">env_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;-&#39;</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_STATES</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span>   <span class="c1"># &#39;-----T&#39; our environment</span>
        <span class="k">if</span> <span class="n">state</span> <span class="o">==</span> <span class="s1">&#39;terminal&#39;</span><span class="p">:</span>
            <span class="n">interaction</span> <span class="o">=</span> <span class="s1">&#39;Round: </span><span class="si">%s</span><span class="s1">     Total_move_steps: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">round</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">step_counter</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">interaction</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">                                &#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">env_list</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span>
            <span class="n">interaction</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">env_list</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">interaction</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FRESH_TIME</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Play_game</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N_STATES</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_STATES</span> <span class="o">=</span> <span class="n">N_STATES</span>   <span class="c1"># the length of the 1 dimensional world</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ACTIONS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">]</span>  <span class="c1"># available actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">EPSILON</span> <span class="o">=</span> <span class="mf">0.9</span>  <span class="c1"># greedy 有多大概率选择最优动作</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_q_table</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_STATES</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ACTIONS</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_q_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_states</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_states</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">))),</span> <span class="n">columns</span><span class="o">=</span><span class="n">actions</span><span class="p">,</span> <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> init q_table: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">table</span>

    <span class="k">def</span> <span class="nf">choose_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">state_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_table</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">EPSILON</span><span class="p">)</span> <span class="ow">or</span> <span class="p">((</span><span class="n">state_actions</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()):</span>
            <span class="n">action_name</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ACTIONS</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>   <span class="c1"># act greedy</span>
            <span class="n">action_name</span> <span class="o">=</span> <span class="n">state_actions</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action_name</span>


<span class="k">class</span> <span class="nc">Train</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learn_round</span><span class="o">=</span><span class="mi">13</span><span class="p">):</span>
        <span class="n">N_STATES</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">game_env</span> <span class="o">=</span> <span class="n">Game_env</span><span class="p">(</span><span class="n">N_STATES</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">Play_game</span><span class="p">(</span><span class="n">N_STATES</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn_round</span> <span class="o">=</span> <span class="n">learn_round</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># learning rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">GAMMA</span> <span class="o">=</span> <span class="mf">0.9</span>  <span class="c1"># discount factor # 远见</span>

    <span class="k">def</span> <span class="nf">learning_round</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="nb">round</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learn_round</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">is_terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">step_count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">game_env</span><span class="o">.</span><span class="n">update_env</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">round</span><span class="p">,</span> <span class="n">step_count</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learning_steps</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">is_terminated</span><span class="p">,</span> <span class="nb">round</span><span class="p">,</span> <span class="n">step_count</span><span class="p">)</span>
            <span class="c1"># print(&quot;\n&quot; + &quot;=&quot; * 20 + &quot;\n q_table round: {}\n&quot;.format(round + 1), self.play.q_table)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">q_table</span>

    <span class="k">def</span> <span class="nf">learning_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">is_terminated</span><span class="p">,</span> <span class="nb">round</span><span class="p">,</span> <span class="n">step_count</span><span class="p">):</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">is_terminated</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">choose_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game_env</span><span class="o">.</span><span class="n">get_env_feedback</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="n">q_predict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">q_table</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">next_state</span> <span class="o">!=</span> <span class="s1">&#39;terminal&#39;</span><span class="p">:</span>
                <span class="n">q_target</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">GAMMA</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">q_table</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">next_state</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>  
            <span class="k">else</span><span class="p">:</span>
                <span class="n">q_target</span> <span class="o">=</span> <span class="n">reward</span>  <span class="c1"># next state is terminal</span>
                <span class="n">is_terminated</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># terminate this episode</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">q_table</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ALPHA</span> <span class="o">*</span> <span class="p">(</span><span class="n">q_target</span> <span class="o">-</span> <span class="n">q_predict</span><span class="p">)</span>  <span class="c1"># update</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>  <span class="c1"># move to next state</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">game_env</span><span class="o">.</span><span class="n">update_env</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">round</span><span class="p">,</span> <span class="n">step_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">step_count</span> <span class="o">+=</span> <span class="mi">1</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">pass</span>
    <span class="c1"># # env show</span>
    <span class="c1"># game_env = Game_env()</span>
    <span class="c1"># action = &quot;left&quot;</span>
    <span class="c1"># next_state, reward = game_env.get_env_feedback(state=4, action=action)</span>
    <span class="c1"># print(&quot;下一个状态:{}\n下一个状态所给予的奖励:{}&quot;.format(next_state, reward))</span>
    <span class="c1"># game_env.update_env(next_state, round=1, step_counter=10)</span>

    <span class="c1"># # play show</span>
    <span class="c1"># play = Play_game()</span>
    <span class="c1"># action = play.choose_action(state=4)</span>
    <span class="c1"># print(&quot;选择的动作名字：&quot;, action)</span>

    <span class="c1"># # learning</span>
    <span class="c1"># agent = Train()</span>
    <span class="c1"># learn_result = agent.learning_round()</span>
    <span class="c1"># print(&quot;\n 最后保存的q_table&quot;, learn_result)</span>
</code></pre></div>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=训练一个可以自己玩游戏的智能体~&amp;url=/2020/03/build-blog-system-by-pelican.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=/2020/03/build-blog-system-by-pelican.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=/2020/03/build-blog-system-by-pelican.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="/tag/reinforcementlearning">ReinforcementLearning</a>                </aside>

                <div class="clear"></div>

                <aside class="post-author">


                        <figure class="post-author-avatar">
                            <img src="https://raw.githubusercontent.com/Mrzhang3389/Mrzhang3389.github.io/master/assets/hold/head.jpg" alt="zh" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="/author/zh">zh</a></h4>
                            <p class="post-author-about">欢迎来到我的blog, 这里用于存放一些成品的项目...</p>
                            <span class="post-author-location"><i class="ic ic-location"></i> ChengDu</span>
                            <span class="post-author-website"><a href="https://Mrzhang3389.github.io"><i class="ic ic-link"></i> Website</a></span>
                        <!-- Social linkes in alphabet order. -->
                            <span class="post-author-github"><a target="_blank" href="https://github.com/Mrzhang3389"><i class="ic ic-link"></i> GitHub</a></span>
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">


          <span class="credits-theme">Theme <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila</a></span>
          <span class="credits-software">Published with <a href="https://github.com/getpelican/pelican" rel="nofollow">Pelican</a></span>
        </section>
      </div>
    </footer>
  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script type="text/javascript" src="/theme/js/script.js"></script>

    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-9028RKV9JT"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-9028RKV9JT', { 'anonymize_ip': true });
    </script>
<script type="text/javascript">
    var disqus_shortname = 'zh3389';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>